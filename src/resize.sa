;
; @file resize.sa
; @author Atlanswer (atlanswer@gmail.com)
; @brief Resize linear assembly implementation.
; @version 0.2
; @date 2020-12-19
; 
; @copyright Copyright (c) 2020
; 
;
        ; Implementation switch
        .if     $isdefed("USE_SA_IMPL")

        .def    resize
resize: .cproc  src, dst, oW, oH, nW, nH, inv_scale
        ; For breaking down inv_scale
        .reg            exponent, mantissa, nexpbase, oneat16
        ; Extract the exponent (bit 31-24).
        extu            inv_scale, 1, 24, exponent
        mvk             127, nexpbase
        sub             exponent, nexpbase, exponent
        ; Extract the mantissa (bit 23-0), but truncated to 15 bits.
        extu            inv_scale, 9, 17, mantissa
        ; Insert 1 to bit 16.
        mvk             1, oneat16
        shl             oneat16, 15, oneat16
        or              oneat16, mantissa, mantissa     ; mantissa << 15
        ; Bring up 0.5, but shifted left by 1
        .reg            f0_5
        mvk             1, f0_5                         ; 0.5 << 1
        ; Row iterator
        .reg            ri
        sub             nH, 1, ri
        ; Column iterator
        .reg            ci
riter:
        sub             nW, 1, ci
        ; Cast index from the new image to the original image.
        ; Formula: sr = (ri + 0.5) * inv_scale - 0.5
        ; Shifting ri left
        .reg            nrishl, rishl, nr0_5shl, r0_5shl, isnrishloverflow
        ; ri + 0.5
        lmbd            1, ri, nrishl
        sub             nrishl, 16, nrishl
        cmpgtu          nrishl, 15, isnrishloverflow
[isnrishloverflow] mvk  15, nrishl
        shl             ri, nrishl, rishl               ; ri << nrishl
        sub             nrishl, 1, nr0_5shl
        shl             f0_5, nr0_5shl, r0_5shl         ; 0.5 << nrishl
        add             rishl, r0_5shl, rishl
        ; * inv_scale
        .reg            srmpyu, srshru
        mpyu            rishl, mantissa, srmpyu         ; sr << nrishl + 15 - exponent
        ; - 0.5
        shru            srmpyu, 15, srshru              ; sr << nrishl - exponent
        sub             srshru, r0_5shl, srshru
        ; u = sr - r
        .reg            u, nsrshru, nsrshl, nsrshlreg, r
        sub             nrishl, exponent, nsrshru       ; nsrshru = nrishl - exponent
        mvk             32, nsrshl
        sub             nsrshl, nsrshru, nsrshl
        shl             nsrshl, 5, nsrshlreg
        add             nsrshlreg, nsrshl, nsrshlreg
        extu            srshru, nsrshlreg, u            ; u << nrishl - exponent
        shru            srshru, nsrshru, r              ; r
        ; Edge handling
        .reg            isrnotoverflow
        cmpltu          r, oH, isrnotoverflow
[!isrnotoverflow] sub   oH, 1, r
[!isrnotoverflow] zero  u
        ; Get u1
        .reg            ircs, ircsr, u1                 ; INTER_RESIZE_COEF_SCALE
        mvk             1, ircs
        shl             ircs, nsrshru, ircsr
        sub             ircsr, u, u1                    ; u1 << nrishl - exponent
        ; Get r_
        .reg            r_, isr_notoverflow
        add             r, 1, r_
        cmpltu          r_, oH, isr_notoverflow
[!isr_notoverflow] sub  oH, 1, r_
        ; Set row pointers
        .reg            pr, pr_
        ldw             *+src[r], pr
        ldw             *+src[r_], pr_
citer:
        ; Formula: sc = (ci + 0.5) * inv_scale - 0.5
        ; Shifting ci left
        .reg            ncishl, cishl, nc0_5shl, c0_5shl, isncishloverflow
        ; ci + 0.5
        lmbd            1, ci, ncishl
        sub             ncishl, 16, ncishl
        cmpgtu          ncishl, 15, isncishloverflow
[isncishloverflow] mvk  15, ncishl
        shl             ci, ncishl, cishl               ; ci << ncishl
        sub             ncishl, 1, nc0_5shl
        shl             f0_5, nc0_5shl, c0_5shl         ; 0.5 << ncishl
        add             cishl, c0_5shl, cishl
        ; * inv_scale
        .reg            scmpyu, scshru
        mpyu            cishl, mantissa, scmpyu         ; sc << ncishl + 15 - exponent
        ; - 0.5
        shru            scmpyu, 15, scshru              ; sc << ncishl - exponent
        sub             scshru, c0_5shl, scshru
        ; v = sc - c
        .reg            v, nscshru, nscshl, nscshlreg, c
        sub             ncishl, exponent, nscshru       ; nscshru = ncishl - exponent
        mvk             32, nscshl
        sub             nscshl, nscshru, nscshl
        shl             nscshl, 5, nscshlreg
        add             nscshlreg, nscshl, nscshlreg
        extu            scshru, nscshlreg, v            ; v << ncishl - exponent
        shru            scshru, nscshru, c              ; c
        ; Edge handling
        .reg            iscnotoverflow
        cmpltu          c, oW, iscnotoverflow
[!iscnotoverflow] sub   oW, 1, c
[!iscnotoverflow] zero  v
        ; Get v1
        .reg            ircsc, v1
        shl             ircs, nscshru, ircsc
        sub             ircsc, v, v1                    ; v1 << ncishl - exponent
        ; Get c_
        .reg            c_, isc_notoverflow
        add             c, 1, c_
        cmpltu          c_, oW, isc_notoverflow
[!isc_notoverflow] sub  oW, 1, c_

        ; Load pixels
        .reg            pxa, pxb, pxc, pxd
        ldbu            *+pr[c], pxa
        ldbu            *+pr[c_], pxb
        ldbu            *+pr_[c], pxc
        ldbu            *+pr_[c_], pxd
        ; Perform interpolation
        ; pxa * u1 * v1
        .reg            pxa32, pxa64h:pxa64l
        mpyu            pxa, u1, pxa32
        mpy32u          v1, pxa32, pxa64h:pxa64l
        ; pxb * u * v1
        .reg            pxb32, pxb64h:pxb64l
        mpyu            pxb, u, pxb32
        mpy32u          v1, pxb32, pxb64h:pxb64l
        .reg            pxc32, pxc64h:pxc64l
        mpyu            pxc, u1, pxc32
        mpy32u          v, pxc32, pxc64h:pxc64l
        .reg            pxd32, pxd64h:pxd64l
        mpyu            pxd, u, pxd32
        mpy32u          v, pxd32, pxd64h:pxd64l
        .reg            pxabh:pxabl
        add             pxa64h, pxb64h, pxabh
        add             pxa64l, pxb64l, pxabl
        .reg            pxcdh:pxcdl
        add             pxc64h, pxd64h, pxcdh
        add             pxc64l, pxd64l, pxcdl
        .reg            pxh:pxl
        add             pxabh, pxcdh, pxh
        add             pxabl, pxcdl, pxl               ; px << nrishl - exponent + ncishl - exponent
        ; Shift result back
        .reg            pxrh:pxrl, npxshru
        sub             nsrshru, exponent, npxshru
        shru            pxh:pxl, npxshru, pxh:pxl       ; px << ncishl
        ; Round to nearest: floor(px + 0.5)
        addu            pxl, c0_5shl, pxrh:pxrl
        add             pxrh, pxh, pxrh
        shru            pxrh:pxrl, ncishl, pxrh:pxrl    ; px
        ; Set row pointers
        .reg            pri
        ldw             *+dst[ri], pri
        ; Store result
        stb             pxrl, *+pri[ci]
        ; Iterate columns
[ci]    bdec            citer, ci
        ; Iterate rows
[ri]    bdec            riter, ri

        .endproc        ; resize

        .endif          ; $isdefed("USE_SA_IMPL")
